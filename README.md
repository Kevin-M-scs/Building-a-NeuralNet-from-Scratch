### Building-a-NeuralNet-from-Scratch
**Author: Kevin M**<br>
This is a simple 2 layer Neural Network with 1 Hidden Layer.<br>
This model has been trained on the MNIST dataset.<br>
For the hidden layer the ReLU Activation function has been used.<br>
Loss function is the Cross Entropy Loss combined with L2 Regularization<br>
For Initialization of the 2 weight matrices the He(Kaiming) initialization method is used.<br>
Please refer to the below video for help regarding the method of calculating the matrix derivatives involved<br>
[Video](https://www.youtube.com/watch?v=pauPCy_s0Ok)<br>
The mathematical details involved in this Neural Network are displayed in Math.jpg<br>







